# Diário (04/08/2025)

## Hoje
- [ ] Escrever o script para a vetorização dos nucleotídeos.

### Script para alocar tempo de GPU no cluster (jupyter notebook com GPU)
```
salloc --partition=partition --nodelist=node --time=00:30:00 # 30 minutos
srun --jobid=$ID --pty bash
ssh -L PORT:localhost:PORT -J USER@HOST USER@NODE
```

### Código de exemplo do EVO2
```python
  import torch
  from evo2 import Evo2
  
  evo2_model = Evo2('evo2_7b')
  
  sequence = 'ACGT'
  input_ids = torch.tensor(
      evo2_model.tokenizer.tokenize(sequence),
      dtype=torch.int,
  ).unsqueeze(0).to('cuda:0')
  
  layer_name = 'blocks.28.mlp.l3'
  
  outputs, embeddings = evo2_model(input_ids, return_embeddings=True, layer_names=[layer_name])
  
  print('Embeddings shape: ', embeddings[layer_name].shape)
```
- Gera o erro:
```python
  RuntimeError: /TransformerEngine/transformer_engine/common/gemm/cublaslt_gemm.cu:412 in function cublas_gemm: cuBLAS Error: an unsupported value or parameter was passed to the function
```

  - **Problema**: GPU é incompatível com FP8
  - **Na documentação:** Note that the 7B checkpoints can be run without FP8, thus avoiding the compute capability requirement. This can be done by modifying the configs to turn off FP8 and is not officially supported as there are numerical differences.
  - **Solução:**
    1. Em:
    ```python
      ./python3.12/site-packages/evo2/configs/evo2-7b-1m.yml
    ```
    2. Mudar o parâmetro `use_fp8_input_projections` para `False`.
      
- Para evitar:
```python
OutOfMemoryError: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 44.42 GiB of which 1.38 MiB is free. Including non-PyTorch memory, this process has 44.41 GiB memory in use. Of the allocated memory 38.88 GiB is allocated by PyTorch, and 5.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
```
  - Usando:
    ```python
    import gc
    import torch
    
    gc.collect()
    torch.cuda.empty_cache()
    ```
    
## Amanhã:
- [x] Identificar e resolver os erros.
- [x] Detalhar erro e solução no diário.
- [x] Terminar de configurar o ambiente.
- [x] Resolver o erro do evo2
- [ ] Continuar a processar os dados.
