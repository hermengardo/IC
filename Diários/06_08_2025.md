# Hoje
Classe para carregar os dados iniciada. Preciso encontrar algo mais eficiente para o método `_load`.

```python
  class JsonlGzBatchLoader:
    def __init__(self) -> None:
        self.file_list = self._get_file_paths()
        self.zipped_batches = self._split_into_batches()
        
    def _unzip_file(self, filepath: str) -> List[str]:
        with gzip.open(filepath, 'rt', encoding='utf-8') as f:
            return f.readlines()

    @property
    def _load(self):
        while len(self.zipped_batches) > 0:
            batch = self.zipped_batches.pop()
            with Pool(processes=CFG.JOBS) as pool:
                unz = pool.map(
                    self._unzip_file,
                    batch
                )

                yield pl.concat([ # Pouco eficiente
                    pl
                    .read_json(StringIO(i))
                    .select(["name", "sequence"])
                    for i in unz[0]])

    def _split_into_batches(self) -> List[List[str]]:
        batches = []
        for i in range(0, len(self.file_list), 50):
            batches.append(self.file_list[i:i+50])
        return batches

    @staticmethod
    def _get_file_paths() -> List[str]:
        return [
            os.path.join(CFG.PATH, f)
            for f in os.listdir(CFG.PATH)
            if f.endswith('.jsonl.gz')
        ]
```

- Como são muitos arquivos, usar um gerador ou estrutura semelhante que permita evitar sobrecarregar a memória é uma boa opção.
- Pelo mesmo motivo, seria interessante encontrar uma forma eficiente para processar tudo (não dá para evitar na hora da extração dos embeddings, mas seria interessante evitar o gargalo na leitura e parsing dos arquivos). 
