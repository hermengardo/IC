# Diário (01/08/2025)

## Hoje
- Configuração do ambiente para a extração dos embeddings usando evo2 no servidor. Solução da instalação para o TransformerEngine:

  **1. Partindo dos *requirements* do evo2:**
  
  ```shell
  conda install -c nvidia cuda-nvcc cuda-cudart-dev
  conda install -c conda-forge transformer-engine-torch=2.3.0
  pip install flash-attn==2.8.0.post2 --no-build-isolation
  ```
  
  **2. O primeiro erro ocorre na linha:**
  
  ```pixi add transformer-engine-torch=2.3.0 ```
  
  - Que produz:
  
  ```shell
  Error:   × failed to solve 'default' for linux-64  
    ├─▶ failed to solve the environment  
    ╰─▶ Cannot solve the request because of: transformer-engine-torch 2.3.0.* cannot be installed because there are no  
        viable options:  
        └─ transformer-engine-torch 2.3 | 2.3 | 2.3 | 2.3 would require  
           └─ python >=3.10,<3.11.0a0, for which no candidates were found.  
        The following packages are incompatible  
        └─ transformer-engine-torch 2.3.0.* cannot be installed because there are no viable options:  
           ├─ transformer-engine-torch 2.3 would constrain  
           │  └─ pytorch * cuda*, which conflicts with any installable versions previously reported  
           └─ transformer-engine-torch 2.3 would constrain  
              └─ pytorch * cuda*, which conflicts with any installable versions previously reported
  ```
              
  - Usar uma versão mais atual do transformer-engine (não declarar a versão) e instalar o torch gera novos erros:
  ```
  fatal error: cudnn.h: No such file or directory
            3 | #include <cudnn.h>
              |          ^~~~~~~~~
        compilation terminated.
        error: command '/opt/ohpc/pub/compiler/gcc/12.2.0/bin/g++' failed with exit code 1
        [end of output]
  ```
  
  - O compilador não consegue encontrar o caminho para três arquivos:
    - *cusparse.h*
    
    - *cudnn.h*  
    
    - *cuda_cmake_macros.h*
  
  - Cada arquivo pode ser encontrado no sistema (ex. ls /usr/local | grep cuda). Os caminhos devem ser adicionados ao ambiente.
  
  **3. Solução completa (em um ambiente recém criado):**
  
  ```shell
  pixi add python=3.12
  pixi add pip
  pixi run pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
  
  module load cuda/12.6
  module load cudnn/8.9
  export CUDA_HOME=$HOME/embeddings/.pixi/envs/default
  export PATH=$CUDA_HOME/bin:$PATH
  export LD_LIBRARY_PATH=$CUDA_HOME/lib:$CUDA_HOME/lib64:$LD_LIBRARY_PATH
  export CPATH=$CUDA_HOME/include:$CPATH
  export LIBRARY_PATH=$CUDA_HOME/lib:$CUDA_HOME/lib64:$LIBRARY_PATH
  
  export CXX=$(which g++)
  
  export CPATH="$CPATH:$(pixi run python -c 'import torch.utils.cpp_extension as ext; print(\":".join(ext.include_paths()))')"
  export CPLUS_INCLUDE_PATH=$CPATH
  
  pixi run pip install --no-build-isolation transformer_engine[pytorch]
  ```

- Depois disso o `requirement` final foi instalado sem erros:
```shell
pixi run pip install flash-attn==2.8.0.post2 --no-build-isolation
```

## Amanhã:
- [x] Identificar e resolver os erros.
- [x] Detalhar erro e solução no diário.
- [ ] Terminar de configurar o ambiente.
- [ ] Continuar a processar os dados

## Nota:
- Como estou usando o pip para instalar os pacotes (não adicionados no .toml), é necessário passar o `pip freeze` para os ambientes.
