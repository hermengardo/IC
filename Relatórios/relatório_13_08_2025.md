# Relatório (13 de Agosto de 2025)

# Objetivo
- Descrever o planejamento para a construção do modelo de regressão.

## Objetivo principal do modelo (main target)
- Seja $G$ um gene composto por $k$ nucleotídeos:

$$
G = \\{ n_1, n_2, \ldots, n_k \\}.
$$

- Seja $\mathbb{V}(G) \in \mathbb{R}^d$ a representação vetorial de $G$, obtida por um modelo de linguagem para proteínas (pLM).

- Seja o conjunto de códons de $G$ definido como:

$$
C = \\{ (n_1, n_2, n_3), (n_4, n_5, n_6), \ldots, (n_{k-2}, n_{k-1}, n_k) \\}.
$$

- Seja $O$ um conjunto de genes ortólogos a $G$.

- Seja $\mathbb{B}$ uma função que estima a probabilidade de a taxa de substituições não sinônimas ($\beta$) exceder a taxa de substituições sinônimas ($\alpha$), dado um códon $c_i \in C$ e genes ortólogos $O$ (onde $\varepsilon_i$ é o erro da estimativa para o i-ésimo códon):

$$
\mathbb{B}(c_i \mid (G, O)) = P(\alpha_i < \beta_i) + \varepsilon_i = P\left[ \left(\frac{dN}{dS}\right)_{c_i} < 1 \\,\middle| (G, O) \right] + \varepsilon_i,
$$

- O objetivo do modelo é encontrar uma função $f: \mathbb{R}^d \to \mathbb{R}^m$ que, dada a representação vetorial $\mathbb{V}(G)$, produza as estimativas de $\mathbb{B}(c_i \mid G, O)$ para todos os $m$ códons de $G$ (onde $\varepsilon_i^*$ é o erro da nova estimativa para o i-ésimo códon):

$$
f(\mathbb{V}(G)) = \left[ P(\alpha_1 < \beta_1) + \varepsilon_1^* , \\, \ldots, \\, P(\alpha_m < \beta_m) + \varepsilon_m^* \right].
$$

- Adicionalmente, busca-se a função $f$ que minimize a soma total dos erros $\varepsilon_i^*$:

$$
\min_{f} \\; L\left[f(\mathbb{V}(G))\right] = \min_{f} \sum_{i=1}^m \varepsilon_i^*
$$

## Função $\mathbb{B}$
- No conjunto de dados, as estimativas da função $\mathbb{B}$ foram calculadas computacionalmente utilizando uma aproximação bayesiana da taxa de seleção diversificadora (MURRELL, 2013) a partir de genes ortólogos de invertebrados.

```shell
    hyphy fubar --code Universal \
            --alignment "./nt_tree_filtered/${prefix}.nt.filtered.fas" \
            --tree "./nwk_filtered/${prefix}.filtered.nwk" \
            --output "./output/${prefix}.filtered.fubar.json" \
            > /dev/null 2>&1
```

# Planejamento do modelo

## Escolha do modelo
- A ideia geral é avaliar modelos que variem em termos de complexidade, custo e arquitetura, como visto na tabela abaixo, indo de modelos tradicionais de aprendizado de máquina até modelos de `deep learning`. Adicionalmente, espera-se avaliar também interações e combinações dos resultados através de um metamodelo (usando a técnica de stacking ensemble).

| Modelo                         | Algoritmo                      | Otimização                      | Função de erro (loss)         | Observação                                                  |
|--------------------------------|---------------------------------|----------------------------------|-------------------------------|-------------------------------------------------------------|
| Dummy Regressor                | -                               | -                                | -                             | Baseline                                                    |
| Regressão Linear               | Regressão linear                | Gradiente Descendente            | Erro Quadrático Médio         | Associação linear (robusto a overfitting)                   |
| Random Forest                  | Ensemble de Árvores de Decisão  | Busca exaustiva de divisões      | Erro Quadrático Médio         | Robusto à multicolinearidade - Associações não lineares      |
| Regressor SGD                  | Regressão linear                | Gradiente Descendente Estocástico| Erro Quadrático Médio         | Associação linear (robusto a overfitting)                   |
| Regressor XGBoost              | Gradient Boosting               | Otimização baseada em gradiente  | Erro Quadrático Médio         | Capaz de lidar com não linearidades e interações complexas   |
| Rede Neural (Shallow Learning) | LSTM, RNN ou MLP              | Adam                             | Erro Quadrático Médio         | Rede neural com não mais do que uma camada                   |
| Rede Neural (Deep Learning)    | LSTM, RNN ou MLP              | Adam                             | Erro Quadrático Médio         | Rede neural com duas ou mais camadas                         |

## Embeddings
- Parte-se do pressuposto que os embeddings de proteína codificam informações evolutivas. Para avaliar se isso é verdadeiro, os vetores serão gerados por três fontes, sendo duas produzidas pelo modelo evo2, na variações com um e sete bilhões de parâmetros, e uma sendo produzida por um modelo dummy (frequencial ou não contextual).
- Para os embeddings gerados pelo evo2, também é de interesse da pesquisa avaliar se a qualidade das representações varia com a profundidade das camadas. Inicialmente, espera-se avaliar a camada do meio (seja $H$ o número de camadas ocultas do modelo, busca-se a representação da camada $\lfloor{\frac{H}{2}}\rfloor$ ou $\lceil{\frac{H}{2}}\rceil$), a penúltima camada ($H-1$) e a última camada ($H$).

## Fine tunning

- Optuna

## Métricas de erro

- MSE

## Validação
- Dos mais de 30 mil genes e famílias que compõe o conjunto de dados total, propõe-se a separação de três conjuntos de treino (subdividido por tamanho, como será visto adiante), um conjunto de validação e um conjunto de teste. Os conjuntos de teste e validação serão filtrados para não conter sequências semelhantes aquelas do conjunto de treino.
- Na ausência de um critério inequívoco para separação dos dados nesses conjuntos, admite-se a proporção mais usual para tarefas de aprendizado de máquina 70% para treino, 20% para teste e 10% para validação (de acordo com o total, ainda na ausência de filtros para eliminar sequências muito semelhantes).
- Para avaliar o impacto da quantidade de dados na qualidade do modelo, o conjunto de treino será subdividido em três conjuntos de treino separados por tamanho (pequeno, médio e grande), na seguintes proporções:
    - Pequeno: 10% do conjunto de treino total
    - Médio: 50% do conjunto de treino total
    - Grande: 100% do conjunto de treino total
 - Dado a transferência de informação obtida nas camadas ocultas da pLM, espera-se que os modelos obtenham resultados não aleatórios (acima do baseline) para os três conjuntos de treino.

## Pipeline

## Pseudocódigo


## Possibilidades (ou coisas que eu ainda não decidir se é uma boa ideia)
- Todos os valores da função $\mathbb{B}$ são acompanhados por um fator de Bayes, que determina a `significância` da estimativa. Para cada gene $G$, a média do fator de Bayes da função $\mathbb{B}$ aplicada em cada códon de G será mapeada para uma variável ordinal, a fim de separar conjuntos de treino conjuntos de dados pelo grau de incerteza da estimativa original. Os `benchmarks` serão executados em todos os conjuntos separadamente, para avaliar o efeito da inclusão de estimativas pouco confiáveis no modelo, e no conjunto total.

## Referências
- MURRELL, B. et al. FUBAR: A Fast, Unconstrained Bayesian AppRoximation for Inferring Selection. Molecular Biology and Evolution, [s. l.], v. 30, ed. 3, p. 1196-1205, 2013. DOI 10.1093/molbev/mst030. Disponível em: https://academic.oup.com/mbe/article-lookup/doi/10.1093/molbev/mst030. Acesso em: 28 jul. 2025.
